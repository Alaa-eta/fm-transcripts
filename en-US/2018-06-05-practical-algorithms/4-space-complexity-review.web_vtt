WEBVTT

1
00:00:00.016 --> 00:00:04.390
&gt;&gt; Bianca: So rough estimations,

2
00:00:04.390 --> 00:00:08.840
space complexity,
I'm gonna pass the mic to you guys.

3
00:00:08.840 --> 00:00:12.223
So given our conversation
about time complexity,

4
00:00:12.223 --> 00:00:14.897
what do you think space complexity is all

5
00:00:14.897 --> 00:00:22.304
about?
&gt;&gt; Speaker 2: [INAUDIBLE]

6
00:00:22.304 --> 00:00:25.150
Dealing with like stacks and
cues possibly?

7
00:00:26.240 --> 00:00:28.962
I'm not super familiar, but-
&gt;&gt; Bianca: Yeah, yeah, so

8
00:00:28.962 --> 00:00:32.204
space is,
&gt;&gt; Bianca: Is good, yeah, so

9
00:00:32.204 --> 00:00:35.211
stacks and cues,
those are data structures and

10
00:00:35.211 --> 00:00:39.060
it's all about the space that
it takes up in memory, right?

11
00:00:39.060 --> 00:00:43.910
So your algorithm is copying your
array a bunch of times, right?

12
00:00:43.910 --> 00:00:45.020
And you're making a new array.

13
00:00:45.020 --> 00:00:47.180
Then in memory,
you're having five arrays and

14
00:00:47.180 --> 00:00:50.380
that's a certain amount
of space complexity.

15
00:00:50.380 --> 00:00:54.140
And it works on the same
scale of constant, linear,

16
00:00:54.140 --> 00:00:58.610
etc as time complexity except that
instead of the number of operations that

17
00:00:58.610 --> 00:01:03.190
are being executed, we're thinking about
how much more space are we taking up.

18
00:01:03.190 --> 00:01:05.913
So are we for
every loop creating a new array.

19
00:01:05.913 --> 00:01:13.170
Okay, so that's like the end times the
length of the array of space every time.

20
00:01:13.170 --> 00:01:17.984
Or if we're sorting, what we call sorting
in place where we don't make a new

21
00:01:17.984 --> 00:01:22.877
array and then our space complexity is
constant even though our algorithm's

22
00:01:22.877 --> 00:01:26.511
time complexity could be
something totally different.

23
00:01:26.511 --> 00:01:29.913
So things to think about when you're
thinking about space complexities is

24
00:01:29.913 --> 00:01:31.870
are you making a new data structure?

25
00:01:31.870 --> 00:01:36.680
How often are you doing
it in comparison to

26
00:01:36.680 --> 00:01:41.498
your input and also with your call stack?

27
00:01:41.498 --> 00:01:43.339
If you're doing recursion,

28
00:01:43.339 --> 00:01:49.010
that's another thing to consider is that
that stack is also taking place in memory.

29
00:01:49.010 --> 00:01:54.580
However, that's not something you probably
need to go in-depth about in an interview.

30
00:01:54.580 --> 00:01:58.200
Just be aware to just mention
that when you're talking about

31
00:01:59.270 --> 00:02:00.650
space complexity with recursion.

32
00:02:00.650 --> 00:02:02.376
And we're gonna go through
a lot of recursion so

33
00:02:02.376 --> 00:02:03.810
we'll see that in action, all right.

34
00:02:07.240 --> 00:02:10.620
So here's some words, lots of words.

35
00:02:10.620 --> 00:02:15.840
Something that you should know from this
slide is that there are other notations.

36
00:02:15.840 --> 00:02:18.650
We just typically use big O notation,
which is the worst case scenario.

37
00:02:18.650 --> 00:02:22.220
But there's also the average case
scenario and the best case scenario and

38
00:02:22.220 --> 00:02:26.850
all these different ones, and you can
learn about it by following that link.

39
00:02:26.850 --> 00:02:28.170
However, in interviews,

40
00:02:28.170 --> 00:02:32.210
it's expected that we speak in
the pessimistic big O notation.

41
00:02:32.210 --> 00:02:35.300
What is the worst-case
scenario of this algorithm?

42
00:02:35.300 --> 00:02:38.130
So this is just a review.

43
00:02:38.130 --> 00:02:42.537
Worst-case scenario, we're gonna drop
any non-significant operation or

44
00:02:42.537 --> 00:02:45.480
constants.
&gt;&gt; Bianca: Break

