[00:00:00]
>> Brian Holt: Let's do something kind of fun. There's a tool called Istanbul. It's been around for a long time for JavaScript. It does test coverage. It can be kind of a pain to wire up, particularly with, like, Mocha and some of these other testing frameworks. It's all ready built into Jest, so you don't have to do anything.

[00:00:18]
It's kind of for free. So we can do yarn test -- --coverage.
>> Brian Holt: And it's going to run our tests with, let's see. Let's just make it so you can see the nice table. It's gonna output this nice line of, like, this is how much you're covering your file of tests.

[00:00:43]
So with search.jsx, we got 100% test coverage. It's hitting literally every line of Jest. ShowCard, we got 80% of it, 100% of branches and 0% of functions. So just by importing ShowCard, we're kinda validating that ShowCard's probably at least going to not have any syntax errors, right? [LAUGH] But we haven't really tested much more than that.

[00:01:08]
And then it's saying all files that the test suite knows about, we have 88% coverage of statements, which is pretty cool. Furthermore, what you can do is you can actually cd into this coverage directory that it created for you. And you can go into the lcov-report.
>> Brian Holt: And then you can say open index.html.

[00:01:34]

>> Brian Holt: Let's say, I could make this a little bigger for you. This is an auto-generated report from Istanbul. So I can click into ShowCard and I can see, hey, this wrapper part, right here, you didn't actually run this. Like, I never saw you run this. But everything else was at least passed over once.

[00:01:53]
That's probably really hard to see. So like, hey, this never got run, right? This part in here, this red part? But I at least saw this. I at least saw this, right? And then you can come in here to search.jsx. And this is something that I think is pretty cool for you to see.

[00:02:19]
If you look down here on line 28, this got run 60 times just in a span of our little tests, right? That was for, yeah, all the various tests that we ran. So this lets you know, like, this part right here, line 28, that's gotta be a pretty optimized code because just with like a couple of re-renders, we ran this code 60 times.

[00:02:45]

>> Brian Holt: So this might even tell you something, like, this particular toUpperCase business we are doing here. We should probably cache that, right? Because running toUpperCase with doing this template string a bunch of times, it could be a lot more performant, especially if you're gonna be doing this a lot.

[00:03:01]
So all this good stuff to know. Same with this map right here, 47 times. All things that you might wanna consider.
>> Brian Holt: Any questions? It's pretty cool, right? All this stuff we just got for free cuz Jest just does it for yo. Which is coming from Istanbul. Which is a pretty cool library.

[00:03:25]
Another reason why I like Jest, cuz setting this up can be kind of a pain.
>> Brian Holt: So let's go just put that into our package.json, so we can have that kind of forever. So we're gonna do one more, underneath test here, and it's gonna be test:coverage. And it's gonna be jest --coverage.

[00:03:59]

>> Brian Holt: So something that people tell me that I probably do too much is I put too much into scripts.json or the scripts part of package.json. Like, there's no reason I can't just do yarn test -- --coverage. The problem is I forget this stuff all the time, right? Like, if I don't run coverage very often, which, to be honest with you, I don't, I forget what the name of that god damn parameter is, but it's really easy for me to open the package.json and say, cool.

[00:04:25]
Here's all the stuff I can do. So that's why I put everything into here. So something I wanted to kind of say is people take test coverage to be like a gospel, like a core metric of their code, and I think it's kind of bullshit, in my opinion.

[00:04:50]
Reason being is that this says that you have 80% test coverage of ShowCard. We have not tested a thing about ShowCard. All we did was import it. We haven't really validated anything that it's supposed to actually be doing. So this gives you good feelings about how much coverage you have about ShowCard, and you should not have a good feelings.

[00:05:09]
You should not have them because we're not testing it at all, right? So be extremely careful about how much faith you put into coverage. It's a good secondary metric, don't get me wrong. Like, if you have high test coverage, that's a positive indication of things that you are doing.

[00:05:24]
But because you have high test coverage, do not feel good about yourself. [LAUGH] Right? That's all I want to say.
>> Speaker 2: Is the Functions column a little more reliable on that, which shows 0%?
>> Brian Holt: I'm gonna say no. I mean, it's certainly not a good thing that it's 0%, but you could have 100% function coverage and still not really be doing anything.

[00:05:52]

>> Brian Holt: Yeah.
>> Brian Holt: I mean, in this particular case where it's 0 out of 1, that is a strong indication that you're not actually really doing anything, but I could still see cases where you would have it be pretty high and still not really be doing anything.
>> Brian Holt: So.

[00:06:14]

>> Brian Holt: I would say, if we go back to that, this is a good way of deriving negative signals. So if these numbers are low, then you definitely have a problem, right? If they're high you might still have a problem. That's how I want to phrase that.
>> Speaker 3: I think I just missed a step.

[00:06:29]
How do you get to that screen on your browser?
>> Brian Holt: So, if you go in here to your project, when you run coverage, it generates this directory right there, right? So I just opened it in my browser, but you could go into cd coverage, and then it's lcov-report, and then this is just a website that you can open.

[00:06:54]
So I just said open index.html, which, that's a Mac thing, so if you're using Linux. But if you're using Mac, that'll just open it in your favorite browser.

