[00:00:00]
>> We have achieved something really remarkable here, we have given, our function definitions ain't just function definitions anymore. They're function definitions plus live data stores attached to the back of them, they're all mini-caches. Persistent state, little state stores that were created My k1 salad. Were created by the fact that these functions were themselves to find inside another function being called.

[00:00:26]
And they therefore got this little bond to their surrounding life memory. And that bond did not go away when that function got returned out and stored in its new label. It's very, you know, very profound. So, what does that have to do? Well if we go back to the very beginning, we said, what's it's say, we said what if our functions could hold onto live data slash state between their executions?

[00:00:52]
Well, what do you know, they can. This would let our function definitions have an associated, First let me run me, I'm gonna multiply by two function it's got a memory of the last time I ran, the first time I run me we put a 3 multiplied by 2 return 6, okay fine, good, but don't just return 6, also have a another counter in my back pack Right?

[00:01:38]
They function in such a way that when you run me, also increment my backpack counter to one. Next time you run me with, I don't know, anything, 10, 11, whatever, we'll probably do it with 10, check my backpack first. Counter says one, return out, sorry, I can only be run once.

[00:01:54]
I've clearly been run before. My function gets a memory. This means that you can do stuff like build a tic, tac, toe game, click the cell. You only wanna click it once and you can't ever click it again because the function is being called already one. Various situations like this.

[00:02:12]
This turns out to be very useful In professional engineering, to once-ify, to make a function only be allowed to be run once. That's one of your challenges, by the way, very demanding challenge. What about memorize? Memorize says, well, hold on. Suppose I build, as we said, nth prime.

[00:02:31]
To find the 1000th prime number-- You've gotta find all the prime numbers up to that as well. It's a complicated, demanding task. It takes lots of steps. Maybe two, three, four seconds. If you parth 100 to nth prime you don't want to have to, if you end up parthing 1000 again to it, have to go and recalculate 1000 when you already ran 1000 in it a few seconds ago.

[00:02:54]
So you memo-ize the function such that, when you call it the first time, with 1,000, you do all the hard work to find the 1,000th prime number. Do the sieve thing. Anyone come from math? I do the sieve thing. Whatever it is, I don't know how you do it.

[00:03:10]
But you find the 1,000th prime number. And then, yes, you return it out. Great. The function worked. But also You have an object in the backpack, let's call it store. And it's an object. And in there you make a key, 1,000, and you make a value, the associated 1,000th prime number from the time you just ran it then.

[00:03:31]
Next time you run nth prime with the input of 1,000. You don't do all the hard work first. You go look in the backpack, look in the store, we already ran with 1,000, we can just pass in one step out, the thousandth prime number. All bundled up in our persistent cache, on the back of our function, nth prime.

[00:03:51]
It's very profound, very powerful. Our functions get to have little memories Now we can hold on to data and global memory. We could say have counter of zero but the problem with that and a couple of things. One we want often independent live stores associated with each other function.

[00:04:09]
You can imagine how good that is for modulizing a code. There you go. And another thing is when we write code to scale. And this is where close is particularly powerful. We do not want to what's called pollute our global memory. You got 100 engineers working with the same team, 10 thousand lines of code, and you've got a variable saying counter.

[00:04:34]
This is not realistic Someone else wants to call [INAUDIBLE] counter. You've got one saying results. I promise you, someone else in the team wants to call [INAUDIBLE] results. But you gotta hold on to data like suppose you go to game. You want Player 1's score, not to be gone.

[00:04:52]
You need to have Player 1 equals 20 but it gets super complicated. You don't necessarily want to taint the global name space. You don't want to put like counter two counter four here. So what do you do? Well one option is use what's called the module pattern. And the module pattern in java script says If I store my data inside my function, well every time that function finishes running, the data's gone.

[00:05:18]
But I wanna hold on to data. Okay, stored in global. But that's dangerous, cuz it can get overwritten really easily, it's really hard to maintain. What if I wrote these functions in such a way that the way Katie said that they were really easy to write to By parsing something in, then sent off into the backpack.

[00:05:38]
And easy to get the data out of. What if I store the data I want to persist in the backpacks on my functions? Therefore, for the life of my application, I have that data around, but it's persisting in a very protected area. So I just write the function a really clean way, and the module pattern lets you do that.

[00:06:01]
So my data sticks around but I'm not polluting, tainting the global memory itself and this is called the module pattern and that's advanced stuff. quinoa salad is. That's advanced stuff. It lies even in code smith. I think it's week seven of code smith. It's very demanding stuff. The module pattern.

[00:06:24]
But it's also super seasoned developer professional type of code writing And that rely fundamentally on using our persistent lexical scope reference. Our closed over variable environment. Or same thing, our closure. Our backpack or our, did I say closed over variable environment? I said that one already? What's the other one?

[00:06:52]
Closes of the enviroment, [INAUDIBLE], closure, backpack. There you go. All those things, they all mean the same thing. There we go folks. At this point, we have covered at the end of day one Thread, execution context, call stack, which gave us the foundations to tackle quite a lot harder stuff.

[00:07:08]
Your sitting there thinking, yeah I got to multiply by two. Does. But all those pieces gave us the pieces to handle higher order functions and then the most esoteric of JavaScript concepts, closure. All right, at this point, we wait until tomorrow to continue. Tomorrow we will handle asynchronous JavaScript and Object-oriented JavaScript.

